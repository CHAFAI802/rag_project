# ðŸ—ï¸ Architecture Documentation

## Overview

This document describes the technical architecture of the RAG Document Search API.

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Client Applications                       â”‚
â”‚                   (Web, Mobile, CLI, SDK)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ HTTP/REST
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FastAPI Server                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  Route Handlers                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ /health      â”‚  â”‚ /api/ingest  â”‚  â”‚ /api/query   â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚            â”‚                  â”‚                  â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Service Layer (Business Logic)                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  RAG Pipeline                                       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - index_document(text, source)                    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - query_rag(question) -> answer                  â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  Document Loader                                    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - load_document(path) -> text                     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Supports: PDF, DOCX, TXT, MD                   â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  Chunker                                            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - chunk_text(text) -> [chunks]                   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - 500 chars per chunk, 100 char overlap          â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚            â”‚                                      â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Core Modules                                  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Embeddings      â”‚  â”‚  VectorStore (FAISS)         â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - embed_texts() â”‚  â”‚  - add(vectors, metadata)    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - embed_query() â”‚  â”‚  - search(vector, k)         â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - HF API Client â”‚  â”‚  - Persists to disk          â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  LLM Module                                          â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - get_llm() -> pipeline (singleton)                â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - generate_answer(context, question)               â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Uses distilgpt2 (lightweight, CPU-friendly)     â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Configuration                                       â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Centralized config via app/core/config.py      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Environment-based secrets                        â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               External Services & Storage                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  HuggingFace API â”‚  â”‚  Local File Storage              â”‚  â”‚
â”‚  â”‚  - Embeddings    â”‚  â”‚  - data/raw_docs/                â”‚  â”‚
â”‚  â”‚  - all-MiniLM    â”‚  â”‚  - data/faiss_index/             â”‚  â”‚
â”‚  â”‚  - 384 dims      â”‚  â”‚  - .env secrets                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Details

### 1. API Layer (`app/api/`)

**Purpose:** HTTP request handling and response formatting

#### `ingest.py`
- **Endpoint:** `POST /api/ingest`
- **Responsibility:** Handle file uploads
- **Flow:**
  1. Validate file (size, format)
  2. Save to disk
  3. Extract text via `DocumentLoader`
  4. Index via `rag_pipeline.index_document()`
  5. Return metadata

**Key Error Handling:**
- File size > 50MB â†’ 413 Payload Too Large
- Empty file â†’ 400 Bad Request
- Unsupported format â†’ 400 Bad Request
- Processing error â†’ 500 Internal Server Error

#### `query.py`
- **Endpoint:** `POST /api/query`
- **Responsibility:** Process user questions
- **Flow:**
  1. Validate input (Pydantic)
  2. Call `rag_pipeline.query_rag()`
  3. Return answer
- **Validation:** question âˆˆ [1, 1000] characters

---

### 2. Service Layer (`app/services/`)

**Purpose:** Business logic and data processing

#### `document_loader.py`
- **Format Support:**
  - **PDF:** Uses PyPDF2
  - **DOCX:** Uses python-docx
  - **TXT/MD:** Direct file reading
- **Returns:** Plain text (UTF-8)
- **Error Handling:** Raises `ValueError` for unsupported formats

#### `chunker.py`
- **Function:** `chunk_text(text, chunk_size=500, overlap=100)`
- **Algorithm:** Sliding window
- **Output:** List of text chunks
- **Guarantee:** No chunk larger than `chunk_size`
- **Overlap:** Ensures context continuity across chunks

**Example:**
```
Text: "ABCDEFGHIJ" (10 chars)
chunk_size=4, overlap=2
Result: ["ABCD", "CDEF", "EFGH", "GHIJ"]
```

#### `rag_pipeline.py`
- **Orchestrates:** Complete RAG workflow
- **Functions:**
  - `index_document(text, source)` - Ingest & index
  - `query_rag(question)` - Search & answer
- **Logging:** Detailed debug info at each step

---

### 3. Core Layer (`app/core/`)

**Purpose:** Infrastructure and low-level operations

#### `config.py`
- **Centralized Configuration**
- **Sources:**
  - Environment variables (.env)
  - Defaults for optional values
- **Content:**
  - API credentials (HF_TOKEN)
  - Model names
  - Hyperparameters
  - Paths (absolute, not relative)

#### `embeddings.py`
- **Embedding Model:** `sentence-transformers/all-MiniLM-L6-v2`
- **Dimension:** 384 (fixed)
- **Provider:** HuggingFace Inference API
- **Functions:**
  - `embed_texts(texts: list[str]) -> NDArray (n, 384)`
  - `embed_query(question: str) -> NDArray (384,)`
- **Returns:** NumPy float32 arrays

#### `vectorstore.py`
- **Backend:** FAISS (IndexFlatL2 - L2 distance)
- **Storage:** 
  - Index: `data/faiss_index/index.faiss`
  - Metadata: `data/faiss_index/metadata.json`
- **Operations:**
  - `add(vectors, metadatas)` - Add to index
  - `search(vector, k=5)` - Retrieve top-k
  - `save()` - Persist to disk
- **Synchronization:** Metadata & index kept in sync

#### `llm.py`
- **Model:** `distilgpt2` (CPU-friendly, 350MB)
- **Pattern:** Singleton (lazy-loaded, thread-safe)
- **Input:** Context + Question
- **Output:** Generated answer
- **Constraint:** Responses grounded in provided context

---

## Data Flow Diagrams

### Ingestion Flow

```
User Upload File
    â”‚
    â–¼
API /ingest (POST)
    â”‚
    â”œâ”€â–¶ Validate (size, format)
    â”‚
    â”œâ”€â–¶ Save to data/raw_docs/
    â”‚
    â”œâ”€â–¶ DocumentLoader.load_document()
    â”‚   â”œâ”€â–¶ PDF extraction (PyPDF2)
    â”‚   â”œâ”€â–¶ DOCX extraction (python-docx)
    â”‚   â””â”€â–¶ TXT/MD direct read
    â”‚
    â”œâ”€â–¶ rag_pipeline.index_document()
    â”‚   â”œâ”€â–¶ Chunker.chunk_text() â†’ [chunks]
    â”‚   â”‚
    â”‚   â”œâ”€â–¶ Embeddings.embed_texts() â†’ vectors
    â”‚   â”‚   â””â”€â–¶ HF Inference API
    â”‚   â”‚
    â”‚   â””â”€â–¶ VectorStore.add()
    â”‚       â”œâ”€â–¶ FAISS add(vectors)
    â”‚       â”œâ”€â–¶ Save metadata JSON
    â”‚       â””â”€â–¶ Persist to disk
    â”‚
    â–¼
Return: {filename, chars, status}
```

### Query Flow

```
User Question
    â”‚
    â–¼
API /query (POST)
    â”‚
    â”œâ”€â–¶ Validate (Pydantic)
    â”‚
    â”œâ”€â–¶ rag_pipeline.query_rag()
    â”‚   â”œâ”€â–¶ Embeddings.embed_query()
    â”‚   â”‚   â””â”€â–¶ HF Inference API
    â”‚   â”‚
    â”‚   â”œâ”€â–¶ VectorStore.search(k=5)
    â”‚   â”‚   â”œâ”€â–¶ FAISS similarity search
    â”‚   â”‚   â””â”€â–¶ Retrieve metadata
    â”‚   â”‚
    â”‚   â”œâ”€â–¶ Context = top-5 chunks
    â”‚   â”‚
    â”‚   â”œâ”€â–¶ LLM.generate_answer()
    â”‚   â”‚   â”œâ”€â–¶ Load model (first time)
    â”‚   â”‚   â”œâ”€â–¶ Create prompt
    â”‚   â”‚   â””â”€â–¶ Generate text
    â”‚   â”‚
    â”‚   â””â”€â–¶ Extract answer from output
    â”‚
    â–¼
Return: {answer}
```

---

## Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **API Framework** | FastAPI | HTTP server, auto-docs |
| **ASGI Server** | Uvicorn | Production-ready server |
| **Request Validation** | Pydantic | Type checking, serialization |
| **Embeddings** | HuggingFace Inference API | Semantic representation |
| **Vector Search** | FAISS | Fast similarity search |
| **LLM** | Transformers + distilgpt2 | Text generation |
| **Document Parsing** | PyPDF2, python-docx | Multi-format support |
| **Data Structure** | NumPy | Vector operations |
| **Testing** | Python unittest | Test automation |
| **Environment** | python-dotenv | Secret management |

---

## Performance Characteristics

### Time Complexity

| Operation | Complexity | Notes |
|-----------|-----------|-------|
| Document ingestion | O(n) | n = document size (chars) |
| Text chunking | O(n) | Linear pass with sliding window |
| Embedding generation | O(n*m) | n = num chunks, m = token length |
| FAISS search | O(log n) | n = num indexed vectors |
| LLM generation | O(k) | k = generated tokens |

### Space Complexity

| Component | Space | Notes |
|-----------|-------|-------|
| FAISS index | 4D bytes | D = 384, 1 vector â‰ˆ 1.5KB |
| Metadata JSON | ~100B/chunk | Source + text excerpt |
| LLM model | 350MB | distilgpt2, loaded once |
| Embeddings cache | O(n*384*4) | n = documents, float32 |

### Benchmark Results (4GB RAM)

| Task | Time | Throughput |
|------|------|-----------|
| PDF extraction | 2-5s | ~1MB/s |
| Chunking | <1s | ~10MB/s |
| Embedding 100 chunks | 2-5s | ~20-50 chunks/s |
| FAISS search | <100ms | ~100 ops/s |
| LLM generation (first) | 20-30s | Model loading |
| LLM generation (cached) | 5-15s | ~50 tokens/s |

---

## State Management

### Persistent State

**Locations:**
- `data/raw_docs/` - Original documents
- `data/faiss_index/index.faiss` - FAISS index
- `data/faiss_index/metadata.json` - Vector metadata

**Consistency:** 
- Atomic writes on save
- Risk: Index corruption if write interrupted
- Mitigation: Could add transaction log

### In-Memory State

**LLM Model:**
- Loaded once, reused for all queries
- Thread-safe singleton pattern
- ~350MB RAM

**FAISS Index:**
- Loaded from disk on first query
- Stays in memory for subsequent queries
- Kept in sync with disk via save()

---

## Error Handling Strategy

### Validation Layer (API)
```
Input Validation (Pydantic)
    â†“
File size check (ingest)
    â†“
Format check (document_loader)
    â†“
Length check (query)
```

### Processing Layer (Services)
```
Try-except blocks
    â†“
Logging (info/warning/error)
    â†“
Graceful fallback or HTTPException
```

### External APIs (HF, FAISS)
```
Network errors â†’ Retry or 503
Model errors â†’ 500 with error message
FAISS errors â†’ Log and raise
```

---

## Security Considerations

### Current Implementation
- âœ… Environment-based secrets (.env)
- âœ… File size validation (50MB limit)
- âœ… File format validation
- âœ… Input length validation

### Recommendations for Production
- ðŸ”’ Add API authentication (API keys or JWT)
- ðŸ”’ Rate limiting per IP/user
- ðŸ”’ Input sanitization (SQL/code injection)
- ðŸ”’ HTTPS/TLS enforcement
- ðŸ”’ CORS configuration
- ðŸ”’ Secrets in environment only (not files)
- ðŸ”’ Regular security audits

---

## Scalability Path

### Current Limits
- **Single instance** on single machine
- **Sequential processing** (no async jobs)
- **File-based storage** (no database)
- **No caching** layer

### Scaling Strategies

**Phase 1: Vertical Scaling**
- Use multi-worker uvicorn
- Increase server RAM

**Phase 2: Horizontal Scaling**
- Load balancer (nginx)
- Multiple API instances
- Shared storage (S3/NFS)
- Shared database (PostgreSQL)

**Phase 3: Async Processing**
- Celery for background jobs
- Redis for task queue
- Webhooks for completion

**Phase 4: Caching**
- Redis for embedding cache
- CDN for static assets

---

## Testing Architecture

### Unit Tests
- Individual function testing
- Mock external dependencies
- Fast execution (<1s)

### Integration Tests
- Multi-component workflow
- Real FAISS operations
- Realistic data

### API Tests
- Endpoint validation
- Request/response format
- Error scenarios

### Coverage Target
- Aim: >80% code coverage
- Tools: coverage.py, pytest

---

## Monitoring & Observability

### Logs
- Structured logging with timestamps
- Log levels: DEBUG, INFO, WARNING, ERROR
- Centralized in app.main

### Metrics (Future)
- Request count/latency
- Error rates
- Model inference time
- Index size

### Health Checks
- `/health` endpoint
- Component status checks
- Readiness probes

---

## Deployment Architecture

### Development
```
Local machine
    â”œâ”€ .venv (virtual environment)
    â”œâ”€ uvicorn --reload
    â””â”€ Local data directory
```

### Staging/Production
```
Cloud instance
    â”œâ”€ Docker container
    â”œâ”€ Multiple uvicorn workers
    â”œâ”€ Nginx reverse proxy
    â”œâ”€ Environment variables (secrets manager)
    â”œâ”€ Persistent volume (data)
    â””â”€ Health checks + auto-restart
```

### CI/CD Pipeline (Future)
```
git push
    â†“
GitHub Actions
    â”œâ”€ Run tests
    â”œâ”€ Run linting
    â”œâ”€ Build Docker image
    â””â”€ Deploy to staging/production
```

---

## References

- [FastAPI Architecture](https://fastapi.tiangolo.com/)
- [FAISS Indexing](https://faiss.ai/)
- [Sentence Transformers](https://www.sbert.net/)
- [RAG Papers](https://arxiv.org/abs/2307.09288)

---

Last updated: January 19, 2026
